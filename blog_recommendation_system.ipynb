{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement\n",
        "The goal of this project/poc is to build a **blog recommendation system** that helps users find blogs similar to the ones they like. The system should:\n",
        "- Analyze blog content to understand key topics and words.\n",
        "- Identify and suggest blogs that have similar content.\n",
        "- Give more importance to recent blogs so that newer content is recommended first.\n",
        "- Ensure recommendations come from the same category as the selected blog.\n",
        "- Allow users to interact and explore recommendations through a simple terminal interface.\n"
      ],
      "metadata": {
        "id": "dyLDSvbZMWjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "BFSsix4BE9ig",
        "outputId": "de297bc4-acc5-4006-ee80-f4c69a8ae238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (0.7.0)\n",
            "Collecting anyio==4.8.0 (from -r requirements.txt (line 2))\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting certifi==2025.1.31 (from -r requirements.txt (line 3))\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: click==8.1.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (8.1.8)\n",
            "Collecting colorama==0.4.6 (from -r requirements.txt (line 6))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.9.0)\n",
            "Collecting exceptiongroup==1.2.2 (from -r requirements.txt (line 8))\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting fastapi==0.115.8 (from -r requirements.txt (line 9))\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: filelock==3.17.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (3.17.0)\n",
            "Collecting fsspec==2024.12.0 (from -r requirements.txt (line 11))\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: h11==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.14.0)\n",
            "Requirement already satisfied: httpcore==1.0.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.0.7)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.28.1)\n",
            "Collecting huggingface-hub==0.28.1 (from -r requirements.txt (line 15))\n",
            "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (3.10)\n",
            "Requirement already satisfied: Jinja2==3.1.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (3.1.5)\n",
            "Requirement already satisfied: jiter==0.8.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (0.8.2)\n",
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (1.4.2)\n",
            "Requirement already satisfied: MarkupSafe==3.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (3.0.2)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (3.4.2)\n",
            "Collecting numpy==2.2.2 (from -r requirements.txt (line 23))\n",
            "  Downloading numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==1.60.2 (from -r requirements.txt (line 24))\n",
            "  Downloading openai-1.60.2-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (24.2)\n",
            "Collecting pandas==2.2.3 (from -r requirements.txt (line 26))\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow==11.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (11.1.0)\n",
            "Requirement already satisfied: pydantic==2.10.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (2.10.6)\n",
            "Requirement already satisfied: pydantic_core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (2.27.2)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r requirements.txt (line 30))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 31))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting pytz==2025.1 (from -r requirements.txt (line 32))\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (6.0.2)\n",
            "Requirement already satisfied: regex==2024.11.6 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (2024.11.6)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (2.32.3)\n",
            "Requirement already satisfied: safetensors==0.5.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 36)) (0.5.2)\n",
            "Requirement already satisfied: scikit-learn==1.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 37)) (1.6.1)\n",
            "Collecting scipy==1.15.1 (from -r requirements.txt (line 38))\n",
            "  Downloading scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six==1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 39)) (1.17.0)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (1.3.1)\n",
            "Collecting starlette==0.45.3 (from -r requirements.txt (line 41))\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl==3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 43)) (3.5.0)\n",
            "Requirement already satisfied: tokenizers==0.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 44)) (0.21.0)\n",
            "Collecting torch==2.6.0 (from -r requirements.txt (line 45))\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio==2.6.0 (from -r requirements.txt (line 46))\n",
            "  Downloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting torchvision==0.21.0 (from -r requirements.txt (line 47))\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 48)) (4.67.1)\n",
            "Collecting transformers==4.48.2 (from -r requirements.txt (line 49))\n",
            "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions==4.12.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 50)) (4.12.2)\n",
            "Requirement already satisfied: tzdata==2025.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 51)) (2025.1)\n",
            "Requirement already satisfied: urllib3==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 52)) (2.3.0)\n",
            "Collecting uvicorn==0.34.0 (from -r requirements.txt (line 53))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 45)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 45)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0->-r requirements.txt (line 45))\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.60.2-py3-none-any.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.1/456.1 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.6.0-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, pytz, nvidia-cusparselt-cu12, uvicorn, python-dotenv, python-dateutil, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fsspec, exceptiongroup, colorama, certifi, anyio, starlette, scipy, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, huggingface-hub, fastapi, torch, openai, transformers, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2024.2\n",
            "    Uninstalling pytz-2024.2:\n",
            "      Successfully uninstalled pytz-2024.2\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.12.14\n",
            "    Uninstalling certifi-2024.12.14:\n",
            "      Successfully uninstalled certifi-2024.12.14\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.27.1\n",
            "    Uninstalling huggingface-hub-0.27.1:\n",
            "      Successfully uninstalled huggingface-hub-0.27.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.59.9\n",
            "    Uninstalling openai-1.59.9:\n",
            "      Successfully uninstalled openai-1.59.9\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu124\n",
            "    Uninstalling torchaudio-2.5.1+cu124:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "langchain 0.3.16 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.8.0 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.2 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.1 which is incompatible.\n",
            "pytensor 2.26.4 requires numpy<2,>=1.17.0, but you have numpy 2.2.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.2 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.2 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anyio-4.8.0 certifi-2025.1.31 colorama-0.4.6 exceptiongroup-1.2.2 fastapi-0.115.8 fsspec-2024.12.0 huggingface-hub-0.28.1 numpy-2.2.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 openai-1.60.2 pandas-2.2.3 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 pytz-2025.1 scipy-1.15.1 starlette-0.45.3 torch-2.6.0 torchaudio-2.6.0 torchvision-0.21.0 transformers-4.48.2 triton-3.2.0 uvicorn-0.34.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "dateutil"
                ]
              },
              "id": "5a3a5199ab7542f598aaf561577f6860"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blog Recommendation System Explanation\n",
        "\n",
        "### 1. TF-IDF is used to convert blog content into numerical vectors.\n",
        "- The **TF-IDF (Term Frequency-Inverse Document Frequency)** technique converts text data into numerical form by evaluating word importance.  \n",
        "- This helps in comparing blogs based on their content rather than just keywords.  \n",
        "\n",
        "### 2. Cosine similarity with NearestNeighbors finds similar blogs.\n",
        "- The **NearestNeighbors model** uses **cosine similarity** to measure how similar two blogs are based on their TF-IDF vectors.  \n",
        "- Blogs with closer cosine similarity scores are considered more relevant to each other.  \n",
        "\n",
        "### 3. Time decay prioritizes recent blogs.\n",
        "- A **time decay factor** is applied using an exponential function to reduce the importance of older blogs.  \n",
        "- This ensures that newer blogs are given more weight in recommendations.  \n",
        "\n",
        "### 4. Topic filtering ensures relevant recommendations.\n",
        "- The system only recommends blogs that share the **same topic** as the selected blog.  \n",
        "- This prevents suggesting irrelevant content, improving user satisfaction.  \n",
        "\n",
        "### 5. Terminal-based interaction allows users to explore blog recommendations dynamically.\n",
        "- Users can **input a blog ID** to get recommendations in an interactive terminal environment.  \n",
        "- The system provides real-time recommendations, allowing users to explore similar content efficiently.  \n",
        "\n"
      ],
      "metadata": {
        "id": "XArmhOr0LyhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "file_path = \"/content/medium_blog_data.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df['scrape_time'] = pd.to_datetime(df['scrape_time'])\n",
        "df['blog_content'] = df['blog_content'].fillna('')"
      ],
      "metadata": {
        "id": "O8g1RlcrIN0G"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_counts_dict = df['topic'].value_counts().to_dict()\n",
        "topic_counts_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXBleqWkINqj",
        "outputId": "844af3a7-2ba4-4b70-9ac2-8a1a61b99771"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ai': 736,\n",
              " 'blockchain': 644,\n",
              " 'cybersecurity': 642,\n",
              " 'web-development': 635,\n",
              " 'data-analysis': 594,\n",
              " 'cloud-computing': 589,\n",
              " 'security': 527,\n",
              " 'web3': 471,\n",
              " 'machine-learning': 467,\n",
              " 'nlp': 453,\n",
              " 'data-science': 444,\n",
              " 'deep-learning': 430,\n",
              " 'android': 426,\n",
              " 'dev-ops': 384,\n",
              " 'information-security': 374,\n",
              " 'image-processing': 354,\n",
              " 'flutter': 343,\n",
              " 'backend': 341,\n",
              " 'cloud-services': 339,\n",
              " 'Cryptocurrency': 331,\n",
              " 'app-development': 322,\n",
              " 'backend-development': 312,\n",
              " 'Software-Development': 309}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "tfidf_matrix = vectorizer.fit_transform(df['blog_content'])\n",
        "\n",
        "# Nearest Neighbors Model\n",
        "nn_model = NearestNeighbors(n_neighbors=10, metric='cosine', algorithm='auto')\n",
        "nn_model.fit(tfidf_matrix)\n",
        "\n",
        "# Normalize timestamps for time decay\n",
        "max_time = df['scrape_time'].max()\n",
        "df['time_decay'] = df['scrape_time'].apply(lambda x: np.exp(-(max_time - x).days / 30))\n",
        "\n",
        "def get_recommendations_advanced(selected_blog_id, previous_recommendations=set()):\n",
        "    idx = df[df['blog_id'] == selected_blog_id].index[0]\n",
        "    distances, indices = nn_model.kneighbors(tfidf_matrix[idx], n_neighbors=10)\n",
        "    selected_blog = df.iloc[idx]\n",
        "    selected_topic = selected_blog['topic']\n",
        "    recommendations = []\n",
        "\n",
        "    for i, distance in zip(indices[0], distances[0]):\n",
        "        recommended_blog = df.iloc[i]\n",
        "        if recommended_blog['blog_id'] != selected_blog_id and recommended_blog['blog_id'] not in previous_recommendations:\n",
        "            if recommended_blog['topic'] == selected_topic:\n",
        "                adjusted_score = (1 - distance) * recommended_blog['time_decay']\n",
        "                recommendations.append((recommended_blog['blog_id'], adjusted_score))\n",
        "\n",
        "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)[:3]\n",
        "    return [r[0] for r in recommendations]\n",
        "\n",
        "def terminal_blog_recommendation_system():\n",
        "    print(\"Welcome to the Terminal-Based Blog Recommendation System!\")\n",
        "    initial_recommendations = df.sample(3)['blog_id'].tolist()\n",
        "    previous_recommendations = set(initial_recommendations)\n",
        "    print(\"\\nHere are some blogs you might like:\")\n",
        "    for blog_id in initial_recommendations:\n",
        "        blog = df[df['blog_id'] == blog_id].iloc[0]\n",
        "        print(f\"- [{blog_id}] {blog['blog_title']} (Topic: {blog['topic']})\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nEnter a blog ID to get recommendations (or type 'exit' to quit): \").strip()\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Thank you for using the recommendation system! Goodbye.\")\n",
        "            break\n",
        "        try:\n",
        "            selected_blog_id = int(user_input)\n",
        "            if selected_blog_id not in df['blog_id'].values:\n",
        "                print(\"Invalid blog ID. Please try again.\")\n",
        "                continue\n",
        "            recommended_blog_ids = get_recommendations_advanced(selected_blog_id, previous_recommendations)\n",
        "            if not recommended_blog_ids:\n",
        "                print(\"No similar blogs found. Try selecting a different blog.\")\n",
        "                continue\n",
        "            print(\"\\nBased on your selection, you might like:\")\n",
        "            for blog_id in recommended_blog_ids:\n",
        "                blog = df[df['blog_id'] == blog_id].iloc[0]\n",
        "                print(f\"- [{blog_id}] {blog['blog_title']} (Topic: {blog['topic']})\")\n",
        "            previous_recommendations.update(recommended_blog_ids)\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a valid blog ID or 'exit' to quit.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    terminal_blog_recommendation_system()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fThSMMpS8Wb",
        "outputId": "afb1ed8e-c642-4922-d83b-2776ff00126e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Terminal-Based Blog Recommendation System!\n",
            "\n",
            "Here are some blogs you might like:\n",
            "- [2129] Unleashing the Potential of Histogram Segmentation for Image Segmentation” (Topic: image-processing)\n",
            "- [1862] Understanding SQL Joins: A Beginner’s Guide with Code Examples (Topic: data-analysis)\n",
            "- [9600] How to improve assertions in Playwright by adding custom matchers (Topic: Software-Development)\n",
            "\n",
            "Enter a blog ID to get recommendations (or type 'exit' to quit): 2129\n",
            "\n",
            "Based on your selection, you might like:\n",
            "- [10232] Histogram Equalisation From Scratch in Python (Topic: image-processing)\n",
            "- [2259] What is Image Segmentation? | Image Processing #9 (Topic: image-processing)\n",
            "- [7056] Image Segmentation in Python (Topic: image-processing)\n",
            "\n",
            "Enter a blog ID to get recommendations (or type 'exit' to quit): 2259\n",
            "\n",
            "Based on your selection, you might like:\n",
            "- [2204] K-Means Clustering for Image Segmentation: An Introduction (Topic: image-processing)\n",
            "- [7075] Deep Learning for Medical Image Segmentation: A Comprehensive Guide (Topic: image-processing)\n",
            "- [7060] How To Restore Images? | Image Processing #7 (Topic: image-processing)\n",
            "\n",
            "Enter a blog ID to get recommendations (or type 'exit' to quit): 1862\n",
            "\n",
            "Based on your selection, you might like:\n",
            "- [6998] SQL Left Join for Data Analysis (Topic: data-analysis)\n",
            "- [6733] Joining the Pieces: How to Use Join Functions to Create a Complete Picture of Your Data (Topic: data-analysis)\n",
            "- [2003] SQL Joins vs Subqueries: What’s the Difference? (Topic: data-analysis)\n",
            "\n",
            "Enter a blog ID to get recommendations (or type 'exit' to quit): 6733\n",
            "\n",
            "Based on your selection, you might like:\n",
            "- [6942] 4 Data Collection Libraries in Python That You Should Know (Topic: data-analysis)\n",
            "- [6778] Python Pandas Fundamentals: Merging data (Topic: data-analysis)\n",
            "- [6921] All About Data Profiling in SQL (Topic: data-analysis)\n",
            "\n",
            "Enter a blog ID to get recommendations (or type 'exit' to quit): 9600\n",
            "\n",
            "Based on your selection, you might like:\n",
            "- [9694] Demystifying High-Level Tests with Cypress (Topic: Software-Development)\n",
            "- [9718] Why API Specs Are the Backbone of Successful Development (Topic: Software-Development)\n",
            "\n",
            "Enter a blog ID to get recommendations (or type 'exit' to quit): 9694\n",
            "No similar blogs found. Try selecting a different blog.\n",
            "\n",
            "Enter a blog ID to get recommendations (or type 'exit' to quit): 9718\n",
            "\n",
            "Based on your selection, you might like:\n",
            "- [9509] Why gRPC is the future of software architecture (Topic: Software-Development)\n",
            "- [9725] 5 Command-Line API Tools You Need To Try (Topic: Software-Development)\n",
            "\n",
            "Enter a blog ID to get recommendations (or type 'exit' to quit): exit\n",
            "Thank you for using the recommendation system! Goodbye.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def precision_at_k(selected_blog_id, recommended_blog_ids, k=3):\n",
        "    selected_topic = df[df['blog_id'] == selected_blog_id]['topic'].values[0]\n",
        "    relevant_count = sum(df[df['blog_id'] == rec_id]['topic'].values[0] == selected_topic for rec_id in recommended_blog_ids)\n",
        "    return relevant_count / k\n",
        "\n",
        "\n",
        "def mean_average_precision(sample_size=100):\n",
        "    sample_blogs = df.sample(sample_size)['blog_id'].tolist()\n",
        "    precisions = [precision_at_k(blog_id, get_recommendations_advanced(blog_id)) for blog_id in sample_blogs]\n",
        "    return np.mean(precisions)\n",
        "\n",
        "\n",
        "def diversity_score(sample_size=100):\n",
        "    sample_blogs = df.sample(sample_size)['blog_id'].tolist()\n",
        "    diversity_scores = []\n",
        "\n",
        "    for blog_id in sample_blogs:\n",
        "        recommended_blog_ids = get_recommendations_advanced(blog_id)\n",
        "        if len(recommended_blog_ids) < 2:\n",
        "            continue\n",
        "\n",
        "\n",
        "        indices = [df[df['blog_id'] == rec_id].index[0] for rec_id in recommended_blog_ids]\n",
        "        sim_matrix = cosine_similarity(tfidf_matrix[indices])\n",
        "        avg_similarity = np.mean(sim_matrix[np.triu_indices(len(indices), k=1)])\n",
        "        diversity_scores.append(1 - avg_similarity)\n",
        "\n",
        "    return np.mean(diversity_scores) if diversity_scores else None\n",
        "\n",
        "\n",
        "precision_k = mean_average_precision()\n",
        "diversity = diversity_score()\n",
        "\n",
        "print(precision_k, diversity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQtyhwcRGTmf",
        "outputId": "f969ca02-347e-43c6-95fc-af98e05d9dcb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.65 0.7448700973372376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Metrics\n",
        "\n",
        "The two computed metrics evaluate different aspects of the blog recommendation system:\n",
        "\n",
        "### **Precision at K (0.65)**\n",
        "\n",
        "- Precision measures how many of the top **K** recommended blogs share the same topic as the selected blog.\n",
        "- A precision of **0.65** means that, on average, **65.00% of the top 3 recommendations** belong to the same topic as the selected blog.\n",
        "- This indicates a **moderate level of relevance** in recommendations.\n",
        "\n",
        "### **Diversity Score (0.74)**\n",
        "\n",
        "- Diversity measures how different the recommended blogs are from each other.\n",
        "- A score of **0.74** means that the recommended blogs are **fairly diverse**, meaning they are not too similar to each other.\n",
        "- This suggests the system provides **varied but still relevant recommendations** rather than overly redundant ones.\n",
        "\n"
      ],
      "metadata": {
        "id": "UQsH6BW9ORLV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D8ZbeusdQRnm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}